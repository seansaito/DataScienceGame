{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for optimizing different classifiers and ensembling them\n",
    "\n",
    "Here is how the algorithm works for training:\n",
    "- Transform the dataset by deleting and adding features\n",
    "- We create 10,000 (adjustable) sets of undersampled data\n",
    "- For each undersampled set, there will be a blend of classifiers:\n",
    "    - Tensorflow\n",
    "    - XGBoost\n",
    "    - RandomForest\n",
    "    - SVM\n",
    "    - ...\n",
    "- For each classifier for each undersampled set, we optimize the hyperparameters\n",
    "- After optimization, we do a small ensemble learning for each undersampled data\n",
    "- Every model is saved\n",
    "\n",
    "For testing:\n",
    "- Transform the dataset\n",
    "- Ensemble classification on the whole dataset (no undersampling)\n",
    "\n",
    "Generating and ensembling predictions\n",
    "- Each model generates the likelihood that the user will convert\n",
    "- Ensembling works by taking a weighted mean of all the votes, the weights being the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# Imports => add any which are necessary\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Preprocessing modules (Shouldn't be needed by now)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Gridsearching and Parameter Optimization\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data\n",
    "X_train_file = \"X_train.npy\"\n",
    "X_valid_file = \"X_valid.npy\"\n",
    "y_train_file = \"y_train.npy\"\n",
    "y_valid_file = \"y_valid.npy\"\n",
    "X_test_file = \"X_test.npy\"\n",
    "\n",
    "X_train = np.load(X_train_file)\n",
    "X_valid = np.load(X_valid_file)\n",
    "y_train = np.load(y_train_file)\n",
    "y_valid = np.load(y_valid_file)\n",
    "X_test = np.load(X_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for setting the parameters\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = {'clf__penalty': ['l1', 'l2'],\n",
    "              'clf__C': param_range,\n",
    "              \"clf__fit_intercept\": [True, False],\n",
    "              \"clf__kernel\": [\"rbf\", \"sigmoid\", \"poly\", \"linear\"],\n",
    "              \"clf__gamma\": param_range}\n",
    "\n",
    "def get_params(*args):\n",
    "    \"\"\"\n",
    "    Returns a list of a dictionary of parameter options\n",
    "    \n",
    "    Usage:\n",
    "        get_params('penalty', 'C', 'kernel')\n",
    "        \n",
    "    Returns:\n",
    "        [{\n",
    "            'clf__penalty': ...,\n",
    "            'clf__C': ...,\n",
    "            'clf__kernel': ...,\n",
    "        }]\n",
    "    \"\"\"\n",
    "    to_return = [{}]\n",
    "    for arg in args:\n",
    "        to_return[0][\"clf__\" + arg] = param_grid[\"clf__\" + arg]\n",
    "    \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the gridsearch\n",
    "cv = 5 # Cross validation\n",
    "n_jobs = -1\n",
    "scoring = \"log_loss\"\n",
    "\n",
    "# Set up the pipeline of your classifier\n",
    "pipe = Pipeline([(\"clf\", RandomForestClassifier())])\n",
    "\n",
    "# Get the params\n",
    "params = get_params(\"penalty\", \"C\")\n",
    "\n",
    "# The GridSearch\n",
    "gs_pipe = GridSearchCV(pipe, params, scoring=scoring, cv=cv, verbose=1, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
