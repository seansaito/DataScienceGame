{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for optimizing different classifiers and ensembling them\n",
    "\n",
    "Here is how the algorithm works for training:\n",
    "- Transform the dataset by deleting and adding features (should be done by this point)\n",
    "- We create N (adjustable) sets of undersampled data (should be done by this point)\n",
    "- For each undersampled set, there will be a blend of classifiers:\n",
    "    - Tensorflow\n",
    "    - XGBoost\n",
    "    - RandomForest\n",
    "    - SVM\n",
    "    - ...\n",
    "- For each classifier for each undersampled set, we optimize the hyperparameters\n",
    "- After optimization, we do a small ensemble learning for each undersampled data\n",
    "- Every model is saved\n",
    "\n",
    "For testing:\n",
    "- Transform the dataset (should be done by this point)\n",
    "- Ensemble classification on the whole dataset (no undersampling)\n",
    "\n",
    "Generating and ensembling predictions\n",
    "- Each model generates the likelihood that the user will convert\n",
    "- Ensembling works by taking a weighted mean of all the votes, the weights being the accuracy of the model.\n",
    "\n",
    "\n",
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# Imports and Global Vars => add any which are necessary\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Preprocessing modules (Shouldn't be needed by now)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Gridsearching and Parameter Optimization\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For efficient saving of models\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data\n",
    "X_train_file = \"data/X_train.npz\"\n",
    "X_valid_file = \"data/X_valid.npy\"\n",
    "y_train_file = \"data/y_train.npz\"\n",
    "y_valid_file = \"data/y_valid.npy\"\n",
    "X_test_file = \"data/X_test.npy\"\n",
    "\n",
    "X_train_clusters = np.load(X_train_file)\n",
    "X_valid = np.load(X_valid_file)\n",
    "y_train_clusters = np.load(y_train_file)\n",
    "y_valid = np.load(y_valid_file)\n",
    "X_test = np.load(X_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for setting the parameters\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = {'clf__penalty': ['l1', 'l2'],\n",
    "              'clf__C': param_range,\n",
    "              \"clf__fit_intercept\": [True, False],\n",
    "              \"clf__kernel\": [\"rbf\", \"sigmoid\", \"poly\", \"linear\"],\n",
    "              \"clf__gamma\": param_range}\n",
    "\n",
    "def get_params(*args):\n",
    "    \"\"\"\n",
    "    Returns a list of a dictionary of parameter options\n",
    "    \n",
    "    Usage:\n",
    "        get_params('penalty', 'C', 'kernel')\n",
    "        \n",
    "    Returns:\n",
    "        [{\n",
    "            'clf__penalty': ...,\n",
    "            'clf__C': ...,\n",
    "            'clf__kernel': ...,\n",
    "        }]\n",
    "    \"\"\"\n",
    "    to_return = [{}]\n",
    "    for arg in args:\n",
    "        to_return[0][\"clf__\" + arg] = param_grid[\"clf__\" + arg]\n",
    "    \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the gridsearch\n",
    "cv = 5 # Cross validation\n",
    "n_jobs = -1\n",
    "scoring = \"log_loss\"\n",
    "\n",
    "# Set up the pipeline of your classifier\n",
    "name = \"LogisticRegression\"\n",
    "pipe = Pipeline([(\"clf\", LogisticRegression())])\n",
    "\n",
    "# Get the params\n",
    "params = get_params(\"penalty\", \"C\")\n",
    "\n",
    "# The GridSearch\n",
    "gs_pipe = GridSearchCV(pipe, params, scoring=scoring, cv=cv, verbose=1, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_60',\n",
       " 'arr_61',\n",
       " 'arr_62',\n",
       " 'arr_63',\n",
       " 'arr_64',\n",
       " 'arr_65',\n",
       " 'arr_66',\n",
       " 'arr_67',\n",
       " 'arr_68',\n",
       " 'arr_69',\n",
       " 'arr_79',\n",
       " 'arr_78',\n",
       " 'arr_77',\n",
       " 'arr_76',\n",
       " 'arr_75',\n",
       " 'arr_74',\n",
       " 'arr_73',\n",
       " 'arr_72',\n",
       " 'arr_71',\n",
       " 'arr_70',\n",
       " 'arr_19',\n",
       " 'arr_18',\n",
       " 'arr_11',\n",
       " 'arr_10',\n",
       " 'arr_13',\n",
       " 'arr_12',\n",
       " 'arr_15',\n",
       " 'arr_14',\n",
       " 'arr_17',\n",
       " 'arr_16',\n",
       " 'arr_82',\n",
       " 'arr_83',\n",
       " 'arr_80',\n",
       " 'arr_81',\n",
       " 'arr_86',\n",
       " 'arr_87',\n",
       " 'arr_84',\n",
       " 'arr_85',\n",
       " 'arr_88',\n",
       " 'arr_89',\n",
       " 'arr_24',\n",
       " 'arr_25',\n",
       " 'arr_26',\n",
       " 'arr_27',\n",
       " 'arr_20',\n",
       " 'arr_21',\n",
       " 'arr_22',\n",
       " 'arr_23',\n",
       " 'arr_28',\n",
       " 'arr_29',\n",
       " 'arr_91',\n",
       " 'arr_90',\n",
       " 'arr_93',\n",
       " 'arr_92',\n",
       " 'arr_95',\n",
       " 'arr_94',\n",
       " 'arr_97',\n",
       " 'arr_96',\n",
       " 'arr_99',\n",
       " 'arr_98',\n",
       " 'arr_33',\n",
       " 'arr_32',\n",
       " 'arr_31',\n",
       " 'arr_30',\n",
       " 'arr_37',\n",
       " 'arr_36',\n",
       " 'arr_35',\n",
       " 'arr_34',\n",
       " 'arr_39',\n",
       " 'arr_38',\n",
       " 'arr_46',\n",
       " 'arr_47',\n",
       " 'arr_44',\n",
       " 'arr_45',\n",
       " 'arr_42',\n",
       " 'arr_43',\n",
       " 'arr_40',\n",
       " 'arr_41',\n",
       " 'arr_48',\n",
       " 'arr_49',\n",
       " 'arr_55',\n",
       " 'arr_54',\n",
       " 'arr_57',\n",
       " 'arr_56',\n",
       " 'arr_51',\n",
       " 'arr_50',\n",
       " 'arr_53',\n",
       " 'arr_52',\n",
       " 'arr_59',\n",
       " 'arr_58',\n",
       " 'arr_1',\n",
       " 'arr_0',\n",
       " 'arr_3',\n",
       " 'arr_2',\n",
       " 'arr_5',\n",
       " 'arr_4',\n",
       " 'arr_7',\n",
       " 'arr_6',\n",
       " 'arr_9',\n",
       " 'arr_8']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clusters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What we actually want to do is generate a gs_pipe for each undersampled set\n",
    "num_examples = len(X_train_clusters.keys())\n",
    "\n",
    "# Group the clusters\n",
    "X_trains = [X_train_clusters[\"arr_{0}\".format(i)] for i in range(num_examples)]\n",
    "y_trains = [y_train_clusters[\"arr_{0}\".format(i)] for i in range(num_examples)]\n",
    "\n",
    "# Create a gridsearch for each dataset\n",
    "gs_pipes = [gs_pipe for i in range(num_examples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n",
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n",
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saito/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:553: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  for parameters in parameter_iterable\n"
     ]
    }
   ],
   "source": [
    "# Now the fun part - hyperparameter search for each model for each undersample\n",
    "\n",
    "X_y_pairs = zip(X_trains, y_trains)\n",
    "data_gs_pipe_pairs = zip(gs_pipes, X_y_pairs)\n",
    "\n",
    "def fit_custom(pair):\n",
    "    gs_pipe, X_y_pair = pair\n",
    "    X_train, y_train = X_y_pair\n",
    "    gs_pipe.fit(X_train, y_train)\n",
    "    return gs_pipe.best_estimator_\n",
    "\n",
    "# Let's do this in parallel\n",
    "from multiprocessing import Pool\n",
    "\n",
    "p = Pool(5)\n",
    "best_classifiers = p.map(fit_custom, data_gs_pipe_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save each sklearn classifier in a folder called clfs\n",
    "filenames = [\"clfs/{name}_{num}.pkl\".format(name=name, num=i) for i in range(num_examples)]\n",
    "\n",
    "for fname, best_clf in zip(filenames, best_classifiers):\n",
    "    joblib.dump(best_clf, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "num_tests = X_test.shape[0]\n",
    "\n",
    "def vote():\n",
    "    predictions = np.zeros((num_tests,1))\n",
    "    for clf in best_classifiers:\n",
    "        probs = clf.predict_proba(X_test)\n",
    "        probs = np.reshape(probs, (num_tests, 1))\n",
    "        predictions = np.hstack(predictions, probs)\n",
    "    means = np.mean(predictions, axis=1)\n",
    "    return means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = vote()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
